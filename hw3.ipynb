{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning homework3\n",
    "\n",
    "Huibo Zhao hz2480\n",
    "Lingjie Xu lx2222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform General Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract those files that contain our training data\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)\n",
    "xlsx_files = [f for f in files if f[-4:] == 'xlsx' and f[0] != '~']\n",
    "\n",
    "# Putting all the contents into dataframe for viewing and accessing\n",
    "df = pd.DataFrame()\n",
    "for f in xlsx_files:\n",
    "    data = pd.read_excel(f, 'FEguide')\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We extract the target value\n",
    "y = df['Comb Unrd Adj FE - Conventional Fuel'].as_matrix()\n",
    "\n",
    "# Examine if the target contains any empty or nan value\n",
    "# If it does, we need to drop the row without a valid target value\n",
    "# Fortunately, we don't find such row\n",
    "for i in y:\n",
    "    if isinstance(i,float) and math.isnan(i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_features = list()\n",
    "\n",
    "\n",
    "# Professor had named a few features that we cannot use, we extract the name of those features\n",
    "da = np.array(df.columns)\n",
    "drop_index = list()\n",
    "for i in range(len(da)):\n",
    "    if \"FE\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "    elif \"MPG\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "    elif \"CO2\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "    elif \"Smog\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "    elif \"Guzzler\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "    elif \"EPA\" in da[i]:\n",
    "        drop_index.append(da[i])\n",
    "\n",
    "dropout_features.extend(drop_index)\n",
    "df_1 = df.drop(drop_index, axis=1) ##########first drop : drop disallowed features##########\n",
    "############################################################################################\n",
    "\n",
    "# We examine each feature and count how many nan values it have\n",
    "# Save results in a dictionary\n",
    "\n",
    "column_names = df_1.columns.values\n",
    "nan_dict = {}\n",
    "\n",
    "for column_name in column_names:\n",
    "    count = 0\n",
    "    for i in range(0,df_1.shape[0]):\n",
    "        if isinstance(df_1.iloc[i][column_name],float) and math.isnan(df_1.iloc[i][column_name]):\n",
    "            count += 1\n",
    "    nan_dict[column_name] = count\n",
    "    \n",
    "drop_2 = list()\n",
    "for key in nan_dict:\n",
    "    if nan_dict[key]>=2000:\n",
    "        drop_2.append(key)\n",
    "\n",
    "dropout_features.extend(drop_2)\n",
    "df_2 = df_1.drop(drop_2, axis=1) ##########second drop : drop features without enough valid entry#########\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Aspir Method: 1973\n",
      "Max Ethanol % - Gasoline: 80\n",
      "Descriptor - Model Type (40 Char or less): 1131\n",
      "Car/Truck Category - Cash for Clunkers Bill.: 1242\n",
      "Unique Label?: 295\n",
      "Label Recalc?: 187\n",
      "Var Valve Timing Desc: 107\n",
      "$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) : 1080\n"
     ]
    }
   ],
   "source": [
    "# After the second drop, we left with 48 features\n",
    "# We found 8 features have at least 1 nan values  \n",
    "# We have to handle that \n",
    "count_dict = {}\n",
    "column_names = df_2.columns.values\n",
    "for column_name in column_names:\n",
    "    count = 0\n",
    "    for i in range(0,df_2.shape[0]):\n",
    "        if isinstance(df_2.iloc[i][column_name],float) and math.isnan(df_2.iloc[i][column_name]):\n",
    "            count += 1\n",
    "    count_dict[column_name] = count\n",
    "    \n",
    "        \n",
    "for key in count_dict:\n",
    "    if count_dict[key] > 0:\n",
    "        print(str(key) + \": \" + str(count_dict[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_features.append(\"Car/Truck Category - Cash for Clunkers Bill.\")\n",
    "df_3 = df_2.drop(\"Car/Truck Category - Cash for Clunkers Bill.\", axis=1) #### third drop ####\n",
    "####### Car/Truck features is useless after examining it ####################################\n",
    "\n",
    "dropout_features.append(\"Release Date\") ###### Fourth drop ##################################\n",
    "df_4 = df_3.drop(\"Release Date\", axis=1) ##### We temporarily drop the date here ############\n",
    "\n",
    "#################### We have done all dropping features by this point #######################\n",
    "#################### All dropout features are stored in dropout_features ####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ = df_4.columns\n",
    "adjust_index = list()\n",
    "adjust_index.append(list(index_).index(\"Max Ethanol % - Gasoline\"))\n",
    "adjust_index.append(list(index_).index(\"Unique Label?\"))\n",
    "adjust_index.append(list(index_).index(\"Label Recalc?\"))\n",
    "adjust_index.append(list(index_).index(\"Var Valve Timing Desc\"))\n",
    "adjust_index\n",
    "\n",
    "for i in adjust_index:\n",
    "    for j in range(df_4.shape[0]):\n",
    "        if j != df_4.shape[0] - 1:\n",
    "            if isinstance(df_4.iat[j, i], float) and math.isnan(df_4.iat[j, i]):\n",
    "                if isinstance(df_4.iat[j + 1, i], float) and math.isnan(df_4.iat[j + 1, i]):\n",
    "                    df_4.iat[j, i] = df_4.iat[j - 1, i]\n",
    "                else:\n",
    "                    m = random.randint(0,1)\n",
    "                    if m == 0:\n",
    "                        df_4.iat[j, i] = df_4.iat[j - 1, i]\n",
    "                    else:\n",
    "                        df_4.iat[j, i] = df_4.iat[j + 1, i]\n",
    "        else:\n",
    "            if isinstance(df_4.iat[j, i],float) and math.isnan(df_4.iat[j, i]):\n",
    "                df_4.iat[j, i] = df_4.iat[j - 1, i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Aspir Method: 1973\n",
      "Descriptor - Model Type (40 Char or less): 1131\n",
      "$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) : 1080\n"
     ]
    }
   ],
   "source": [
    "count_dict = {}\n",
    "column_names = df_4.columns.values\n",
    "for column_name in column_names:\n",
    "    count = 0\n",
    "    for i in range(0,df_4.shape[0]):\n",
    "        if isinstance(df_4.iloc[i][column_name],float) and math.isnan(df_4.iloc[i][column_name]):\n",
    "            count += 1\n",
    "    count_dict[column_name] = count\n",
    "    \n",
    "        \n",
    "for key in count_dict:\n",
    "    if count_dict[key] > 0:\n",
    "        print(str(key) + \": \" + str(count_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_4.to_csv('4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_3.columns.values)\n",
    "column_names = df_3.columns.values\n",
    "type(column_names)\n",
    "\n",
    "count_dict = {}\n",
    "\n",
    "\n",
    "for column_name in column_names:\n",
    "    print(column_name)\n",
    "    count = 0\n",
    "    #print(df.iloc[0][column_name])\n",
    "\n",
    "    for i in range(0,df_3.shape[0]):\n",
    "        if isinstance(df_3.iloc[i][column_name],float) and math.isnan(df_3.iloc[i][column_name]):\n",
    "            count += 1\n",
    "    count_dict[column_name] = count\n",
    "\n",
    "\n",
    "    \n",
    "#print(nan_dict)\n",
    "\n",
    "\n",
    "test = list()\n",
    "for key in count_dict:\n",
    "    if count_dict[key]> 0:\n",
    "        test.append(key)\n",
    "        \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in count_dict:\n",
    "    if count_dict[key] > 0:\n",
    "        print(str(key) + \": \" + str(count_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_4 = df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = df_4.columns\n",
    "k = list(index_1).index(\"$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) \")\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_4 = df_4.drop(\"Release Date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_4 = pd.get_dummies(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_4['$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) '] = pd.to_numeric(df_4['$ You Spend over 5 years (increased amount spent in fuel costs over 5 years - on label) '], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.to_csv('4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_4.as_matrix()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1623]\n",
    "# for j in range(df_4.shape[0]):\n",
    "#     if isinstance(df_3.iat[j, 44], float) and math.isnan(df_3.iat[j, 44]):\n",
    "#         df_4.iat[j, 44] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fancyimpute\n",
    "mice = fancyimpute.MICE(verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "logreg=LogisticRegression()\n",
    "linearreg=LinearRegression()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_fancy_mice = mice.complete(X_train)\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_fancy_mice)\n",
    "X_train_scaled = scaler.transform(X_train_fancy_mice)\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(linearreg, X_train_scaled, y_train, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fancy_mice[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
